{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tysonp\\Anaconda3\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "with open(\"data/best_model/lfm_with_itemfeats_best.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "with open(\"data/best_model/train_user_items.pkl\", \"rb\") as f:\n",
    "    train_user_items = pickle.load(f)\n",
    "with open(\"data/best_model/item_features.pkl\", \"rb\") as f:\n",
    "    item_features = pickle.load(f)\n",
    "with open(\"data/best_model/encode_streamer.pkl\", \"rb\") as f:\n",
    "    encode_streamer = pickle.load(f)\n",
    "    \n",
    "decode_streamer = {encode_streamer[x]:x for x in encode_streamer}\n",
    "n_items = 1904"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I retrieved my follows from the Twitch API and saved them to `data/my_follows.txt`\n",
    "with open(\"data/my_follows.txt\", \"r\") as f:\n",
    "    my_follows = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: LightFM does not define a method to get similar items like the Implicit package. We implement it below by following the answer here https://github.com/lyst/lightfm/issues/244."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trainwreckstv', 'pokelawls', 'Mizkif', 'm0xyy', 'Lacari']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def similar_items(item_id, item_features, model, N=5):\n",
    "    N += 1 # generate N+1 recommendations and remove the item_id\n",
    "    item_representations = item_features.dot(model.item_embeddings)\n",
    "\n",
    "    # Cosine similarity\n",
    "    scores = item_representations.dot(item_representations[item_id, :])\n",
    "    item_norms = np.linalg.norm(item_representations, axis=1)\n",
    "    scores /= item_norms\n",
    "\n",
    "    best = np.argpartition(scores, -N)[-N:]\n",
    "    best_tuples = sorted(zip(best, scores[best] / item_norms[item_id]), key=lambda x: -x[1])\n",
    "    return [decode_streamer[x] for x,i in best_tuples if x != item_id][:N]\n",
    "\n",
    "similar_items(item_id=encode_streamer[\"xQcOW\"], item_features=item_features, model=model, N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Voyboy', 'Scarra', 'Jankos', 'Gosu', 'shroud']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend_by_user_CF(follows_ID, N=5):\n",
    "    # generate interaction vector\n",
    "    interactions = np.zeros(n_items)\n",
    "    for ind in follows_ID:\n",
    "        interactions[ind] = 1\n",
    "\n",
    "    # get most similar user in training data\n",
    "    user_sim_scores = cosine_similarity(interactions.reshape(1,-1), train_user_items)\n",
    "    most_sim_user_ID = np.argmax(user_sim_scores)\n",
    "\n",
    "    # make recommendations\n",
    "    recs = model.predict(user_ids=[most_sim_user_ID], item_ids=list(range(n_items)), \\\n",
    "                    user_features=None, item_features=item_features)\n",
    "    recs = [(decode_streamer[i],x) for i,x in enumerate(recs) if i not in follows_ID] # convert streamer_ID back to streamer_name\n",
    "    recs = sorted(recs, key=lambda x: -x[1])[:N] # sort by score\n",
    "    recs = list(list(zip(*recs))[0]) # remove the scores \n",
    "    \n",
    "    return recs\n",
    "\n",
    "recommend_by_user_CF(follows_ID=[encode_streamer[x] for x in my_follows if x in encode_streamer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shroud', 'Voyboy', 'Gosu', 'Jankos', 'tarzaned']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend_by_user_CF2(follows_ID, N=5, m=5):\n",
    "    \"\"\" A generalization of recommend_by_user_CF where we identify the top m similar users\n",
    "        and compute final recommendations by weighting each similar users recommendations. We use the\n",
    "        formula: $final_recs = \\sum_{u=1}^m \\frac{recs_u}{u}$. That is, users which are deemed less\n",
    "        similar are weighted less.\n",
    "        \n",
    "        When m=1, this is equivalent to recommend_by_user_CF.\n",
    "    \"\"\"\n",
    "    \n",
    "    # generate interaction vector\n",
    "    interactions = np.zeros(n_items)\n",
    "    for ind in follows_ID:\n",
    "        interactions[ind] = 1\n",
    "\n",
    "    # get most similar user in training data\n",
    "    user_sim_scores = cosine_similarity(interactions.reshape(1,-1), train_user_items).reshape(-1)\n",
    "    most_sim_user_IDs = np.argsort(-user_sim_scores)[:m] # top m similar users\n",
    "   \n",
    "    # make recommendations\n",
    "    d = np.zeros(n_items)\n",
    "    for scale,ID in enumerate(most_sim_user_IDs, start=1):\n",
    "        recs = model.predict(user_ids=ID, item_ids=np.arange(n_items), \\\n",
    "                        user_features=None, item_features=item_features)\n",
    "        d += recs/scale\n",
    "        \n",
    "    recs = d  \n",
    "    recs = [(decode_streamer[i],x) for i,x in enumerate(recs) if i not in follows_ID] # convert streamer_ID back to streamer_name\n",
    "    recs = sorted(recs, key=lambda x: -x[1])[:N] # sort by score\n",
    "    recs = list(list(zip(*recs))[0]) # remove the scores \n",
    "    \n",
    "    return recs\n",
    "\n",
    "recommend_by_user_CF2(follows_ID=[encode_streamer[x] for x in my_follows if x in encode_streamer], m=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(follows, N=5):\n",
    "    if len(follows) < 1:\n",
    "        return \"Enter a streamer\"\n",
    "    \n",
    "    else:\n",
    "        follows_ID = [encode_streamer[x] for x in follows if x in encode_streamer]\n",
    "        if len(follows_ID) < 1:\n",
    "            return \"No streamers found in our database\"\n",
    "        elif len(follows_ID) == 1:\n",
    "            return similar_items(item_id=follows_ID[0], item_features=item_features, model=model, N=N)\n",
    "        else:\n",
    "            return recommend_by_user_CF(follows_ID, N=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a streamer\n",
      "['Trainwreckstv', 'pokelawls', 'Mizkif', 'm0xyy', 'Lacari']\n",
      "['Voyboy', 'Scarra', 'Jankos', 'Gosu', 'shroud']\n"
     ]
    }
   ],
   "source": [
    "# test 1: 0 follows\n",
    "print(recommend([]))\n",
    "\n",
    "# test 2: 1 follow\n",
    "print(recommend([\"xQcOW\"] ))\n",
    "\n",
    "# test 3: > 1 follow\n",
    "print(recommend(my_follows))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
